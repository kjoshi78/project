{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VkparbLMFKd"
      },
      "source": [
        "install ML Flow and Pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wzdiWQogMoO",
        "outputId": "c6984be8-b73e-44bb-c66b-0b948796c7c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB-zNCaNMKtj",
        "outputId": "19f8c27d-fc8e-4add-e8af-9d77beb25e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting mlflow-skinny==2.18.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.0.3)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (17.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.18.0->mlflow)\n",
            "  Downloading databricks_sdk-0.38.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.2)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (4.25.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.18.0-py3-none-any.whl (27.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.38.0-py3-none-any.whl (575 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.1/575.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 databricks-sdk-0.38.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.18.0 mlflow-skinny-2.18.0 pyngrok-7.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cEGzQq8fPAwx"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_NGROK_AUTH_TOKEN' with your actual ngrok auth token\n",
        "NGROK_AUTH_TOKEN = \"2pxHlMNtK2iGSk5UR3tu2ParHYK_3PFbLonHA2PfPskLiCFfL\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ItahfP8HPHD1"
      },
      "outputs": [],
      "source": [
        "# Start the MLflow UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asCB_L6zQN_m",
        "outputId": "094f9275-f7d5-45ec-acd4-6a2af9a48aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://3ea9-34-143-151-44.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "# Kill any existing ngrok tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Open a new HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFRKoxJUJuQz",
        "outputId": "3d95d9f9-104b-44eb-88cc-fff9d7fa8b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/926.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A_h7LB1Ltah"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WHbrXcjOLtaj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "# Pytorch package\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.feature_extraction import get_graph_node_names, create_feature_extractor\n",
        "\n",
        "#Image packages\n",
        "from PIL import Image\n",
        "import mlflow\n",
        "import torchmetrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJx46hU5R0Qz",
        "outputId": "bbaaa412-0da7-48d0-f816-d1ac51acdef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/12/10 15:50:59 INFO mlflow.tracking.fluent: Experiment with name '2024-12-10_15-50-59' does not exist. Creating a new experiment.\n",
            "2024/12/10 15:50:59 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.5.1, but the installed version is 2.5.1+cu121. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n"
          ]
        }
      ],
      "source": [
        "# Set experiment name\n",
        "#get date\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "# Format the date and time as a string (e.g., \"2024-12-09_12-00-00\")\n",
        "experiment_name = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "mlflow.set_experiment(\"\" + experiment_name)\n",
        "mlflow.pytorch.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aM5m_tXLtak",
        "outputId": "92fec0f5-137d-4daa-f15c-3561cd8e015e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check device availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"You are using device: %s\" % device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl-LcxMOLtak"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1jz4TXP2Ltal"
      },
      "outputs": [],
      "source": [
        "# mydir = os.getcwd()\n",
        "mydir = '/content/drive/MyDrive/project/'\n",
        "train_dir = os.path.join(mydir, 'chest_xray', 'train')\n",
        "test_dir = os.path.join(mydir, 'chest_xray', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZpYclM3sLtal"
      },
      "outputs": [],
      "source": [
        "mean_nums = [0.485, 0.456, 0.406]\n",
        "std_nums = [0.229, 0.224, 0.225]\n",
        "\n",
        "cnn_transforms =  T.Compose([\n",
        "                        T.Resize(256),\n",
        "                        T.CenterCrop(224),\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize(mean=mean_nums, std=std_nums),\n",
        "                    ])\n",
        "\n",
        "# data_transforms = {\"train\": transforms.Compose([\n",
        "#                                             transforms.Resize(256),\n",
        "#                                             transforms.CenterCrop(224),\n",
        "#                                             transforms.ToTensor(),\n",
        "#                                             transforms.Normalize(mean=mean_nums, std=std_nums),\n",
        "#                                         ]),\n",
        "#                     \"test\": transforms.Compose([\n",
        "#                                 transforms.Resize(256),\n",
        "#                                 transforms.CenterCrop(224),\n",
        "#                                 transforms.ToTensor(),\n",
        "#                                 transforms.Normalize(mean=mean_nums, std=std_nums),\n",
        "#                             ]),}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL2oY0jySwk6",
        "outputId": "7a9be392-3119-4813-92da-2fcdcad60b3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "os.path.exists(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wSkrlbK3Ltal"
      },
      "outputs": [],
      "source": [
        "def create_split_train_val_test(train_dir, test_dir, transforms, val_size=0.15):\n",
        "    train_data = datasets.ImageFolder(train_dir,\n",
        "                    transform=transforms)\n",
        "    test_data = datasets.ImageFolder(test_dir,\n",
        "                    transform=transforms)\n",
        "    train_subset, val_subset = torch.utils.data.random_split(train_data, [1-val_size, val_size], generator=torch.Generator().manual_seed(1))\n",
        "    torch.save(train_subset, mydir+'/train_data.pt')\n",
        "    torch.save(val_subset, mydir+'/val_data.pt')\n",
        "    torch.save(test_data, mydir+'/test_data.pt')\n",
        "\n",
        "def load_data(dir, batch_size=64):\n",
        "    train_data = torch.load(os.path.join(dir, 'train_data.pt'))\n",
        "    val_data = torch.load(os.path.join(dir, 'val_data.pt'))\n",
        "    test_data = torch.load(os.path.join(dir, 'test_data.pt'))\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=3)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size, num_workers=3)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=batch_size, num_workers=3)\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iAkF5_I9Ltal"
      },
      "outputs": [],
      "source": [
        "create_split_train_val_test(train_dir, test_dir, cnn_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKXvvzkaLtal",
        "outputId": "b2bf4cb9-8cb2-4175-dc69-1dd32752b1ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-c70a5cbcdf4e>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_data = torch.load(os.path.join(dir, 'train_data.pt'))\n",
            "<ipython-input-14-c70a5cbcdf4e>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  val_data = torch.load(os.path.join(dir, 'val_data.pt'))\n",
            "<ipython-input-14-c70a5cbcdf4e>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_data = torch.load(os.path.join(dir, 'test_data.pt'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = load_data(mydir, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "efIHHV5zLtam"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\"train\":train_loader, \"val\":val_loader}\n",
        "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MJ-FjbetLtam"
      },
      "outputs": [],
      "source": [
        "class_names = train_loader.dataset.dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cqojoiEaO6Ps"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute precision, recall, and F1 score using sklearn metrics.\n",
        "    \"\"\"\n",
        "    # Initialize precision, recall, and F1 score trackers for multi-class classification\n",
        "    precision_metric = torchmetrics.Precision(num_classes=2, average='macro',task='binary').to(device)  # adjust num_classes\n",
        "    recall_metric = torchmetrics.Recall(num_classes=2, average='macro',task='binary').to(device)\n",
        "    f1_metric = torchmetrics.F1Score(num_classes=2, average='macro',task='binary').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import io\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix'):\n",
        "    \"\"\"Plot confusion matrix as a heatmap.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    ax.set_xlabel('Predicted')\n",
        "    ax.set_ylabel('True')\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(\"ConfusionMatrix.png\", format='png')\n",
        "    return \"ConfusionMatrix.png\""
      ],
      "metadata": {
        "id": "5cI0yFEeRb7n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvwgDyEoLtam"
      },
      "source": [
        "## Model Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4PEnWKnhUX1f"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, data_sizes, criterion, optimizer, scheduler, device, batch_size, num_epochs=10):\n",
        "    # Start the MLflow run\n",
        "    with mlflow.start_run():\n",
        "\n",
        "        # Log model hyperparameters\n",
        "        params = {\n",
        "            \"epochs\": num_epochs,\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "            \"batch_size\": batch_size,\n",
        "            \"loss_function\": type(criterion).__name__,\n",
        "            \"scheduler\": type(scheduler).__name__,\n",
        "            \"optimizer\": type(optimizer).__name__,\n",
        "            \"model\": type(model).__name__\n",
        "        }\n",
        "        mlflow.log_params(params)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        best_loss = np.inf\n",
        "\n",
        "        # Training Loop\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluation mode\n",
        "\n",
        "                current_loss = 0.0\n",
        "                current_corrects = 0\n",
        "                all_preds = []\n",
        "                all_labels = []\n",
        "\n",
        "                for inputs, labels in tqdm.tqdm(dataloaders[phase], desc=phase, leave=False):\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        scheduler.step()\n",
        "\n",
        "                    current_loss += loss.item() * inputs.size(0)\n",
        "                    current_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                    # Collect all predictions and labels for metrics calculation\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                # Calculate loss and accuracy for this epoch\n",
        "                epoch_loss = current_loss / data_sizes[phase]\n",
        "                epoch_acc = current_corrects.double() / data_sizes[phase]\n",
        "\n",
        "                # Calculate precision, recall, and F1 score\n",
        "                precision, recall, f1 = compute_metrics(all_labels, all_preds)\n",
        "\n",
        "                # Log metrics to MLflow\n",
        "                mlflow.log_metric(f'{phase}_loss', epoch_loss, step=epoch)\n",
        "                mlflow.log_metric(f'{phase}_accuracy', epoch_acc, step=epoch)\n",
        "                mlflow.log_metric(f'{phase}_precision', precision, step=epoch)\n",
        "                mlflow.log_metric(f'{phase}_recall', recall, step=epoch)\n",
        "                mlflow.log_metric(f'{phase}_f1_score', f1, step=epoch)\n",
        "\n",
        "                # Print epoch results\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} | {phase} Accuracy: {epoch_acc:.4f}')\n",
        "                print(f'{phase} Precision: {precision:.4f} | {phase} Recall: {recall:.4f} | {phase} F1 Score: {f1:.4f}')\n",
        "\n",
        "                if phase == 'val':\n",
        "                    print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(phase, epoch_loss, phase, epoch_acc))\n",
        "                    mlflow.log_metric(\"val_loss\", epoch_loss, step=epoch+1)\n",
        "                    mlflow.log_metric(\"val_acc\", epoch_acc, step=epoch+1)\n",
        "\n",
        "                    if epoch == num_epochs-1:\n",
        "                       # Log confusion matrix for validation phase\n",
        "                       cm = confusion_matrix(all_labels, all_preds)\n",
        "                       cm_img_buf = plot_confusion_matrix(cm, class_names)\n",
        "                       mlflow.log_artifact(cm_img_buf, f\"confusion_matrix_val_epoch_{epoch+1}.png\")\n",
        "\n",
        "                else:\n",
        "                    print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(phase, epoch_loss, phase, epoch_acc))\n",
        "                    mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch+1)\n",
        "                    mlflow.log_metric(\"train_acc\", epoch_acc, step=epoch+1)\n",
        "\n",
        "                    if epoch == num_epochs-1:\n",
        "                        # Log confusion matrix for training phase\n",
        "                        cm = confusion_matrix(all_labels, all_preds)\n",
        "                        cm_img_buf = plot_confusion_matrix(cm, class_names)\n",
        "                        mlflow.log_artifact(cm_img_buf, f\"confusion_matrix_train_epoch_{epoch+1}.png\")\n",
        "\n",
        "                # Early stopping: Save the best model\n",
        "                if phase == 'val' and epoch_loss < best_loss:\n",
        "                    print(f'Val loss decreased from {best_loss:.4f} to {epoch_loss:.4f}. Saving weights...')\n",
        "                    best_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            print()\n",
        "\n",
        "        # Record the time spent training\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best validation loss: {best_loss:.4f}')\n",
        "\n",
        "        # Log final metrics to MLflow\n",
        "        mlflow.log_metric(\"best_val_loss\", best_loss)\n",
        "        mlflow.log_metric(\"training_time\", time_elapsed)\n",
        "\n",
        "        # Load the best model weights\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Save the model to MLflow\n",
        "        mlflow.pytorch.log_model(model, \"model\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC1Xogb5Ltam"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    mlflow.start_run()\n",
        "    params = {\n",
        "        \"epochs\": num_epochs,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"batch_size\": batch_size,\n",
        "        \"loss_function\": type(criterion).__name__ ,\n",
        "        \"scheduler\": type(scheduler).__name__,\n",
        "        \"optimizer\": type(optimizer).__name__,\n",
        "        \"model\": type(model).__name__\n",
        "    }\n",
        "    mlflow.log_params(params)\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = np.inf\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10) # Log model hyperparameters\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            current_loss = 0.0\n",
        "            current_corrects = 0\n",
        "\n",
        "            for inputs, labels in tqdm.tqdm(dataloaders[phase], desc=phase, leave=False):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # We need to zero the gradients in the Cache.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Time to carry out the forward training poss\n",
        "                # We only need to log the loss stats if we are in training phase\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                # We want variables to hold the loss statistics\n",
        "                current_loss += loss.item() * inputs.size(0)\n",
        "                current_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = current_loss / data_sizes[phase]\n",
        "            epoch_acc = current_corrects.double() / data_sizes[phase]\n",
        "            if phase == 'val':\n",
        "                print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(\n",
        "                    phase, epoch_loss, phase, epoch_acc))\n",
        "            else:\n",
        "                print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(\n",
        "                    phase, epoch_loss, phase, epoch_acc))\n",
        "\n",
        "            # EARLY STOPPING\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print('Val loss Decreased from {:.4f} to {:.4f} \\nSaving Weights... '.format(best_loss, epoch_loss))\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_since = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_since // 60, time_since % 60))\n",
        "    print('Best val loss: {:.4f}'.format(best_loss))\n",
        "    mlflow.log_metric(\"best_val_loss\", best_loss)\n",
        "    mlflow.log_metric(\"training_time\", time_since)\n",
        "\n",
        "    # Now we'll load in the best model weights and return it\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # Save the trained model to MLflow.\n",
        "    mlflow.pytorch.log_model(model, \"model\")\n",
        "    return model\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJcpZubyLtan"
      },
      "source": [
        "## Densenet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuMFIvACJyt8",
        "outputId": "ae8cd086-974b-4f8e-8531-85c9be357bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7MCABUw3Bj_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uX2eO-DkLtan"
      },
      "outputs": [],
      "source": [
        "def Densenet_Model(class_names, pretrained=True):\n",
        "    if pretrained:\n",
        "        model = models.densenet121(weights='DEFAULT')\n",
        "    else:\n",
        "        model = models.densenet121(weights=None)\n",
        "\n",
        "    for params in model.parameters():\n",
        "        params.requires_grad=False\n",
        "    num_ftrs = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(num_ftrs, len(class_names))\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47PMSelAbtUz",
        "outputId": "524a9c91-2cb8-46ae-fbcb-a7d991fb795a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with lr=1e-05, gamma=0.1, step_size=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 163MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Accuracy: 73.66524949653167\n",
            "Training with lr=1e-05, gamma=0.1, step_size=10\n",
            "Avg Accuracy: 74.69008726784514\n",
            "Training with lr=1e-05, gamma=0.1, step_size=15\n",
            "Avg Accuracy: 71.79458491832625\n",
            "Training with lr=1e-05, gamma=0.5, step_size=5\n",
            "Avg Accuracy: 73.92257775788768\n",
            "Training with lr=1e-05, gamma=0.5, step_size=10\n",
            "Avg Accuracy: 75.38599239203401\n",
            "Training with lr=1e-05, gamma=0.5, step_size=15\n",
            "Avg Accuracy: 74.62967106735289\n",
            "Training with lr=1e-05, gamma=0.9, step_size=5\n",
            "Avg Accuracy: 74.74379055717162\n",
            "Training with lr=1e-05, gamma=0.9, step_size=10\n",
            "Avg Accuracy: 74.46408592526292\n",
            "Training with lr=1e-05, gamma=0.9, step_size=15\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the training function for Ray Tune\n",
        "def train_model(lr, gamma, step_size, train_loader, device,num_epochs):\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize model, loss function, optimizer\n",
        "    dense_model = Densenet_Model(class_names, pretrained=True).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(dense_model.parameters(), lr=lr)\n",
        "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    # Training loop (simplified)\n",
        "    num_epochs = 10\n",
        "    total_accuracy = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        dense_model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Ensure data is on the same device as the model\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = dense_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        exp_lr_scheduler.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = 100 * correct / total\n",
        "        total_accuracy += accuracy\n",
        "        #tune.report(accuracy=accuracy)  # Report accuracy to Ray Tune\n",
        "    return total_accuracy / num_epochs  # Return average accuracy\n",
        "\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "\n",
        "# Example Hyperparameter Search Space (Grid Search)\n",
        "learning_rates = [1e-5, 1e-4, 1e-3]  # Learning rates to try\n",
        "gammas = [0.1, 0.5, 0.9]  # Gamma values for learning rate decay\n",
        "step_sizes = [5, 10, 15]  # Step sizes for LR scheduler\n",
        "\n",
        "# Initialize training configurations\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Assume `train_loader` is predefined (data loading should be done earlier)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Grid Search over all combinations of hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for gamma in gammas:\n",
        "        for step_size in step_sizes:\n",
        "            print(f\"Training with lr={lr}, gamma={gamma}, step_size={step_size}\")\n",
        "\n",
        "            # Train the model with current hyperparameters\n",
        "            avg_accuracy = train_model(lr, gamma, step_size, train_loader, device, 10)\n",
        "            print(f\"Avg Accuracy: {avg_accuracy}\")\n",
        "\n",
        "            # Update the best parameters if the current run is better\n",
        "            if avg_accuracy > best_accuracy:\n",
        "                best_accuracy = avg_accuracy\n",
        "                best_params = {'lr': lr, 'gamma': gamma, 'step_size': step_size}\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Accuracy: {best_accuracy}\")\n",
        "\n",
        "# Get the best hyperparameters\n",
        "#print(\"Best Hyperparameters: \", analysis.best_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfY4l1WMgnVQ",
        "outputId": "05fe9309-e38e-4625-8b4c-a0df434d2e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDyodCBLLtan",
        "outputId": "b33fe594-dd6b-4ffc-9644-a777d2fa31ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: \n",
            "2050\n"
          ]
        }
      ],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in dense_model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "MAAgGSvALtan",
        "outputId": "0c5cc320-291d-4958-c9ee-78ac608d44ae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8b504748c128>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_densenet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
          ]
        }
      ],
      "source": [
        "best_densenet_model = train_model(dense_model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "56dc2650c6cc4078a4628e006c21bcec",
            "3889d227c01c48d9b1ddf78534c84985",
            "edf0c29d90a246aebc310eb3eb72db73",
            "a38bb7e49c9348219c4c57b5ae296adb",
            "44fb5f059b8944b5a172bf9fab873810",
            "08c52b318d164ac09d087fe3eb4cc05a",
            "084c36c94bd54cebb9de9c27765dc7bb",
            "decd370bee214a79a1e25aa535a1a482",
            "1c98df08accc4f3c8de06458e8441665",
            "6743934d77d944a1a1170ceaa358f0b5",
            "7f6fc31fddf946bcb7eaadfcc03d3f6d"
          ]
        },
        "id": "J9LYiIF-Ltan",
        "outputId": "6015c5c5-e47d-4b65-909c-6fcca67953ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56dc2650c6cc4078a4628e006c21bcec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "test_loss = 0.0\n",
        "test_corrects = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in tqdm.tqdm(test_loader, leave=False):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        y_test_pred = best_densenet_model(x_batch)\n",
        "        y_test_pred = torch.log_softmax(y_test_pred, dim=1)\n",
        "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
        "        loss = criterion(y_test_pred, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "        test_corrects += torch.sum(y_pred_tag == y_batch.data)\n",
        "\n",
        "test_loss = test_loss / len(test_loader.sampler)\n",
        "test_acc = test_corrects.double() / len(test_loader.sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfMvsLAdLtan",
        "outputId": "f378de31-15f3-40ca-caf2-d3f1b71cfb4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.691200350339596\n",
            "tensor(0.6250, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(test_loss)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suTCv4JELtan"
      },
      "outputs": [],
      "source": [
        "torch.save(best_densenet_model.state_dict(), 'best_densenet_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0ejoPX1Cuy4"
      },
      "outputs": [],
      "source": [
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_9-dERMLtao"
      },
      "source": [
        "## Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3M1Iu1lLtao"
      },
      "outputs": [],
      "source": [
        "def Resnet_Model(class_names, pretrained=True):\n",
        "    if pretrained:\n",
        "        model = models.resnet50(weights='DEFAULT')\n",
        "    else:\n",
        "        model = models.resnet50(weights=None)\n",
        "    for params in model.parameters():\n",
        "        params.requires_grad=False\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "res_model = Resnet_Model(class_names, pretrained=True)\n",
        "\n",
        "# specify loss function (categorical cross-entropy loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Specify optimizer which performs Gradient Descent\n",
        "optimizer = optim.Adam(res_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Learning Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX9DOY9gLtao",
        "outputId": "0ec69683-a00c-4ae1-c245-672bc6a97ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: \n",
            "4098\n"
          ]
        }
      ],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in res_model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "LGS04G6hLtao",
        "outputId": "bb90a071-14ab-45cc-84ea-82f65f2938cd"
      },
      "outputs": [
        {
          "ename": "Exception",
          "evalue": "Run with UUID 79d74391e3e949c9ab0a4d4c5277840a is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-49ebdead0ece>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_resnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-8c239c6b3086>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     params = {\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mexperiment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_run_stack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         raise Exception(\n\u001b[0m\u001b[1;32m    345\u001b[0m             (\n\u001b[1;32m    346\u001b[0m                 \u001b[0;34m\"Run with UUID {} is already active. To start a new run, first end the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Run with UUID 79d74391e3e949c9ab0a4d4c5277840a is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
          ]
        }
      ],
      "source": [
        "best_resnet_model = train_model(res_model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c83da62756864717ab58060475021988"
          ]
        },
        "id": "Vu-FWRWqLtao",
        "outputId": "f91f4926-8753-490f-811a-8f4c79ad551d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c83da62756864717ab58060475021988",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "test_loss = 0.0\n",
        "test_corrects = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in tqdm.tqdm(test_loader, leave=False):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        y_test_pred = best_resnet_model(x_batch)\n",
        "        y_test_pred = torch.log_softmax(y_test_pred, dim=1)\n",
        "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
        "        loss = criterion(y_test_pred, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "        test_corrects += torch.sum(y_pred_tag == y_batch.data)\n",
        "\n",
        "test_loss = test_loss / len(test_loader.sampler)\n",
        "test_acc = test_corrects.double() / len(test_loader.sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rsypo6kLtao",
        "outputId": "8291260f-81a4-4b30-e076-a38a897213e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.635118889885071\n",
            "tensor(0.6250, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(test_loss)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxVgI5Y_Ltao"
      },
      "outputs": [],
      "source": [
        "torch.save(best_resnet_model.state_dict(), 'best_resnet_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFpKv_i6Ltao"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3KEeg67Ltao"
      },
      "outputs": [],
      "source": [
        "def Transformer_Model(class_names, pretrained=True):\n",
        "    if pretrained:\n",
        "        model = models.vit_b_16(weights='DEFAULT')\n",
        "    else:\n",
        "        model = models.resnet50(weights=None)\n",
        "\n",
        "    weights = models.ViT_B_16_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    #Freeze transformer\n",
        "    for params in model.parameters():\n",
        "        params.requires_grad=False\n",
        "\n",
        "    num_ftrs = model.hidden_dim\n",
        "    model.heads = nn.Linear(num_ftrs, len(class_names))\n",
        "    model = model.to(device)\n",
        "    return model, transforms\n",
        "\n",
        "transformer_model, transformer_transforms = Transformer_Model(class_names, pretrained=True)\n",
        "\n",
        "# specify loss function (categorical cross-entropy loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Specify optimizer which performs Gradient Descent\n",
        "optimizer = optim.Adam(transformer_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Learning Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uabe951MLtao",
        "outputId": "16592dfb-6c33-4317-8e20-48ffa75f5d24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p-lZiwrLtap",
        "outputId": "6d9c92d6-6351-4490-854d-786f705d4335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: \n",
            "1538\n"
          ]
        }
      ],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in transformer_model.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOd_s9z6Ltap"
      },
      "outputs": [],
      "source": [
        "create_split_train_val_test(train_dir, test_dir, transformer_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_vH8rhPLtap",
        "outputId": "5a160f72-0182-45e4-bf85-0c80298c460e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rohil\\AppData\\Local\\Temp\\ipykernel_13828\\3774757452.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_data = torch.load(os.path.join(dir, 'train_data.pt'))\n",
            "C:\\Users\\rohil\\AppData\\Local\\Temp\\ipykernel_13828\\3774757452.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  val_data = torch.load(os.path.join(dir, 'val_data.pt'))\n",
            "C:\\Users\\rohil\\AppData\\Local\\Temp\\ipykernel_13828\\3774757452.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_data = torch.load(os.path.join(dir, 'test_data.pt'))\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = load_data(mydir, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_acVWd1Ltaq"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\"train\":train_loader, \"val\":val_loader}\n",
        "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "70c08ef561de44d7b065c8bee528f0f7",
            "addc7176af5f4c1086bb1ce82c7e69a8",
            "d8c9891e874b4bffb08b3e7aca938417",
            "1ce352acde1e4534a688b2b0d0d3f081",
            "9298305c53b446b4a3d71f848c4eef12",
            "f4a6d78a15ab448cb962db894f6c78be",
            "64f0ee4fcbd7498ea2d5d8efe79ffb09",
            "20d684491b8f426f96c7e7d719191095",
            "01925bd0c70b41128f05cf0e9ce519b7",
            "82e95b4b682d4113874bd02cb107274d",
            "207b6a909b404b42a3f0369da9751ef5",
            "4808452ee9894b62be9b846c4c1b65ef",
            "a50a017156a04c778a9908b1dbe681c3",
            "b0bfdb3480224052a765591c508c1160",
            "4ccddb4e70924056b95da549c0d8395c",
            "0ea4405400d4490b815e64aaab4e8f04",
            "21b6a7c9d1e34c6893f95ff0c1776252",
            "5e037578ea16450eb12f2ebdd80b7dcd",
            "a8a9fd860f7345e58a5e50f5de108942",
            "440739b6bf4941b2b841e02e595ba23c"
          ]
        },
        "id": "1oKGPQMuLtaq",
        "outputId": "4f5db827-e099-42cd-dbf0-77f3de2e3c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70c08ef561de44d7b065c8bee528f0f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rohil\\anaconda3\\envs\\cs7643-a3\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3177 | train Accuracy: 0.8934\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "addc7176af5f4c1086bb1ce82c7e69a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "Val loss Decreased from inf to 0.2980 \n",
            "Saving Weights... \n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8c9891e874b4bffb08b3e7aca938417",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ce352acde1e4534a688b2b0d0d3f081",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9298305c53b446b4a3d71f848c4eef12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4a6d78a15ab448cb962db894f6c78be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64f0ee4fcbd7498ea2d5d8efe79ffb09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20d684491b8f426f96c7e7d719191095",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01925bd0c70b41128f05cf0e9ce519b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82e95b4b682d4113874bd02cb107274d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "207b6a909b404b42a3f0369da9751ef5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4808452ee9894b62be9b846c4c1b65ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "Val loss Decreased from 0.2980 to 0.2980 \n",
            "Saving Weights... \n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a50a017156a04c778a9908b1dbe681c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0bfdb3480224052a765591c508c1160",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ccddb4e70924056b95da549c0d8395c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ea4405400d4490b815e64aaab4e8f04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21b6a7c9d1e34c6893f95ff0c1776252",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e037578ea16450eb12f2ebdd80b7dcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "Val loss Decreased from 0.2980 to 0.2980 \n",
            "Saving Weights... \n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8a9fd860f7345e58a5e50f5de108942",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3019 | train Accuracy: 0.9080\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "440739b6bf4941b2b841e02e595ba23c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2980 | val Accuracy: 0.9094\n",
            "\n",
            "Training complete in 23m 60s\n",
            "Best val loss: 0.2980\n"
          ]
        }
      ],
      "source": [
        "best_transformer_model = train_model(transformer_model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b4c7592c617d4b31923ea963a28276e2"
          ]
        },
        "id": "qML00UUDLtaq",
        "outputId": "ffb0a1ca-f41f-43b4-fd49-5298f5b7b849"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4c7592c617d4b31923ea963a28276e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "test_loss = 0.0\n",
        "test_corrects = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in tqdm.tqdm(test_loader, leave=False):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        y_test_pred = best_transformer_model(x_batch)\n",
        "        y_test_pred = torch.log_softmax(y_test_pred, dim=1)\n",
        "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
        "        loss = criterion(y_test_pred, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "        test_corrects += torch.sum(y_pred_tag == y_batch.data)\n",
        "\n",
        "test_loss = test_loss / len(test_loader.sampler)\n",
        "test_acc = test_corrects.double() / len(test_loader.sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aekdhku_Ltaq",
        "outputId": "2b12c47f-11c6-455b-dd0d-e4d8cff57678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4429000127009856\n",
            "tensor(0.7804, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(test_loss)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG88MTf2Ltaq"
      },
      "outputs": [],
      "source": [
        "torch.save(best_transformer_model.state_dict(), 'best_transformer_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrX6nYKSLtaq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtoa5umkLtaq"
      },
      "source": [
        "## Hybrid Resnet + Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yxMxloGLtaq"
      },
      "outputs": [],
      "source": [
        "class hybrid_model(nn.Module):\n",
        "    def __init__(self, vit_model, resnet_model, dropout=0.3, device=device):\n",
        "        super().__init__()\n",
        "        self.vit_model = vit_model.to(device)\n",
        "        self.vit_linear = nn.Linear(768, 2048, device=device)\n",
        "\n",
        "        self.resnet_model = resnet_model.to(device)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear1 = nn.Linear(4096, 500, device=device)\n",
        "        self.linear2 = nn.Linear(500, 2, device=device)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        vit_result = self.vit_model(inputs)['getitem_5']\n",
        "        vit_result = self.vit_linear(vit_result)\n",
        "\n",
        "        res_result = self.resnet_model(inputs)\n",
        "        res_result = torch.reshape(res_result, (res_result.shape[0], res_result.shape[1]))\n",
        "\n",
        "        output = torch.cat((vit_result, res_result), 1)\n",
        "        output = self.dropout(output)\n",
        "        output = self.linear1(output)\n",
        "        output = self.dropout(output)\n",
        "        output = self.linear2(output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDcDiHvdLtaq"
      },
      "outputs": [],
      "source": [
        "def hybrid(class_names):\n",
        "    resnet_model = models.resnet50(weights='DEFAULT')\n",
        "    vit_model = models.vit_b_16(weights='DEFAULT')\n",
        "\n",
        "    # Remove the last layer of Resnet\n",
        "    resnet_layers = list(resnet_model.children())\n",
        "    resnet_model = nn.Sequential(*resnet_layers[:-1])\n",
        "\n",
        "    for params in resnet_model.parameters():\n",
        "        params.requires_grad=False\n",
        "\n",
        "\n",
        "    for params in vit_model.parameters():\n",
        "        params.requires_grad=False\n",
        "\n",
        "    vit_model_top = create_feature_extractor(vit_model, return_nodes=['getitem_5'])\n",
        "    model = hybrid_model(vit_model_top, resnet_model, 0.3, device)\n",
        "\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "hmodel = hybrid(class_names)\n",
        "\n",
        "# specify loss function (categorical cross-entropy loss)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Specify optimizer which performs Gradient Descent\n",
        "optimizer = optim.Adam(hmodel.parameters(), lr=1e-3)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Learning Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1BUs_MgLtar"
      },
      "outputs": [],
      "source": [
        "full_train_df = {}\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "i = 0\n",
        "for label in labels:\n",
        "    path = os.path.join(train_dir, label)\n",
        "    for img in os.listdir(path):\n",
        "        full_train_df[i] = [os.path.join(path, img), label]\n",
        "        i += 1\n",
        "\n",
        "full_train_df = pd.DataFrame.from_dict(data=full_train_df, orient='index', columns=['file_path','labels'])\n",
        "train_df = full_train_df.sample(frac=0.85, random_state=42).sample(frac=1.0, random_state=42)\n",
        "val_df = full_train_df.drop(train_df.index).sample(frac=1.0, random_state=42)\n",
        "\n",
        "\n",
        "test_df = {}\n",
        "i = 0\n",
        "for label in labels:\n",
        "    path = os.path.join(test_dir, label)\n",
        "    for img in os.listdir(path):\n",
        "        test_df[i] = [os.path.join(path, img), label]\n",
        "        i += 1\n",
        "\n",
        "test_df = pd.DataFrame.from_dict(data=test_df, orient='index', columns=['file_path','labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwPaM66oLtar"
      },
      "outputs": [],
      "source": [
        "create_split_train_val_test(train_dir, test_dir, transformer_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rx1MHssLtar",
        "outputId": "bff1725b-7d67-42d6-c82f-46d5f8ed7ed5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rohil\\AppData\\Local\\Temp\\ipykernel_13828\\3774757452.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_data = torch.load(os.path.join(dir, 'train_data.pt'))\n",
            "C:\\Users\\rohil\\AppData\\Local\\Temp\\ipykernel_13828\\3774757452.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  val_data = torch.load(os.path.join(dir, 'val_data.pt'))\n",
            "C:\\Users\\rohil\\AppData\\Local\\Temp\\ipykernel_13828\\3774757452.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_data = torch.load(os.path.join(dir, 'test_data.pt'))\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = load_data(mydir, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okb556YuLtar"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\"train\":train_loader, \"val\":val_loader}\n",
        "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP09vwgyLtar",
        "outputId": "7b6baa40-5b23-43be-fb7d-5a5f4181a151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trainable parameters: \n",
            "3624414\n"
          ]
        }
      ],
      "source": [
        "pytorch_total_params = sum(p.numel() for p in hmodel.parameters() if p.requires_grad)\n",
        "print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjDYN_ZoLtar"
      },
      "outputs": [],
      "source": [
        "def train_hybrid_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = np.inf\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            current_loss = 0.0\n",
        "            current_corrects = 0\n",
        "\n",
        "            for inputs, labels in tqdm.tqdm(dataloaders[phase], desc=phase, leave=False):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # We need to zero the gradients in the Cache.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Time to carry out the forward training poss\n",
        "                # We only need to log the loss stats if we are in training phase\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                # We want variables to hold the loss statistics\n",
        "                current_loss += loss.item() * inputs.size(0)\n",
        "                current_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = current_loss / data_sizes[phase]\n",
        "            epoch_acc = current_corrects.double() / data_sizes[phase]\n",
        "            if phase == 'val':\n",
        "                print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(\n",
        "                    phase, epoch_loss, phase, epoch_acc))\n",
        "            else:\n",
        "                print('{} Loss: {:.4f} | {} Accuracy: {:.4f}'.format(\n",
        "                    phase, epoch_loss, phase, epoch_acc))\n",
        "\n",
        "            # EARLY STOPPING\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print('Val loss Decreased from {:.4f} to {:.4f} \\nSaving Weights... '.format(best_loss, epoch_loss))\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_since = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_since // 60, time_since % 60))\n",
        "    print('Best val loss: {:.4f}'.format(best_loss))\n",
        "\n",
        "    # Now we'll load in the best model weights and return it\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8d8baabafc88448a9f87ecb278bdbae2",
            "259220642b8d4ca5af00fc3500d5e131",
            "a1c50f07fc8049219a0743f873dd582a",
            "d52758e0e1e548079297b75a057aceec",
            "eea551d25e2b476ab77a52cb462742e6",
            "034db72f55084fb8b1807cf8d9dc23ba",
            "ae00e0df344241f3bcd84d5e53e0b366",
            "7384fb94b2034b9498e9e2af0772dd93",
            "dc9659e5e3894565a1e0fbf2e536ffc3",
            "3e6b7862d00f4a1b9ef5c4a5806b6212",
            "09c4f86e361246beb97ed21812f1f736",
            "f62b1e18980a47d6952e5c348c1b60a9",
            "ff23eeb8536446cea03e9c827bc93ad7",
            "222f7afb753c4391af7a803c9092c0a9",
            "9c44d0e427654b7690a1a463682952a4",
            "9992c1953b6b41119dd9470c71a26b33",
            "538146d3773a45dcb8d7134a4d82544e",
            "05eb1fb3923b42708291d9685119848e",
            "dc1a0a720d7c465995e28b86c7db9cf7",
            "0a12b0e8cb7f42d4b36e36c7f18f35c2"
          ]
        },
        "id": "6XlEjBk5Ltas",
        "outputId": "f350a045-a97d-4e66-d631-de3a5297446d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d8baabafc88448a9f87ecb278bdbae2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3748 | train Accuracy: 0.9049\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "259220642b8d4ca5af00fc3500d5e131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2769 | val Accuracy: 0.9260\n",
            "Val loss Decreased from inf to 0.2769 \n",
            "Saving Weights... \n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1c50f07fc8049219a0743f873dd582a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2745 | train Accuracy: 0.9256\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d52758e0e1e548079297b75a057aceec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2794 | val Accuracy: 0.9260\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eea551d25e2b476ab77a52cb462742e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2731 | train Accuracy: 0.9247\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "034db72f55084fb8b1807cf8d9dc23ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2792 | val Accuracy: 0.9273\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae00e0df344241f3bcd84d5e53e0b366",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2725 | train Accuracy: 0.9258\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7384fb94b2034b9498e9e2af0772dd93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2788 | val Accuracy: 0.9273\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc9659e5e3894565a1e0fbf2e536ffc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2727 | train Accuracy: 0.9265\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e6b7862d00f4a1b9ef5c4a5806b6212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2784 | val Accuracy: 0.9286\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09c4f86e361246beb97ed21812f1f736",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2758 | train Accuracy: 0.9258\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f62b1e18980a47d6952e5c348c1b60a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2810 | val Accuracy: 0.9247\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff23eeb8536446cea03e9c827bc93ad7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2735 | train Accuracy: 0.9260\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "222f7afb753c4391af7a803c9092c0a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2802 | val Accuracy: 0.9260\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c44d0e427654b7690a1a463682952a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2708 | train Accuracy: 0.9258\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9992c1953b6b41119dd9470c71a26b33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2793 | val Accuracy: 0.9273\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "538146d3773a45dcb8d7134a4d82544e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2717 | train Accuracy: 0.9265\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05eb1fb3923b42708291d9685119848e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2782 | val Accuracy: 0.9286\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc1a0a720d7c465995e28b86c7db9cf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/70 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2713 | train Accuracy: 0.9254\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a12b0e8cb7f42d4b36e36c7f18f35c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "val:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.2790 | val Accuracy: 0.9273\n",
            "\n",
            "Training complete in 26m 21s\n",
            "Best val loss: 0.2769\n"
          ]
        }
      ],
      "source": [
        "best_hybrid_model = train_hybrid_model(hmodel, criterion, optimizer, exp_lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "bb2c221e62db47988765ea7c3394479c"
          ]
        },
        "id": "LRp2eA_bLtas",
        "outputId": "a6803239-0315-400b-8c23-8aa4c36fb3c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb2c221e62db47988765ea7c3394479c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred_list = []\n",
        "y_true_list = []\n",
        "test_loss = 0.0\n",
        "test_corrects = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in tqdm.tqdm(test_loader, leave=False):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        y_test_pred = best_hybrid_model(x_batch)\n",
        "        y_test_pred = torch.log_softmax(y_test_pred, dim=1)\n",
        "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
        "        loss = criterion(y_test_pred, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "        test_corrects += torch.sum(y_pred_tag == y_batch.data)\n",
        "\n",
        "test_loss = test_loss / len(test_loader.sampler)\n",
        "test_acc = test_corrects.double() / len(test_loader.sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9KT56izLtas",
        "outputId": "9da5b2bb-19c9-4d45-eede-13fd754ef15e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.803626088377757\n",
            "tensor(0.8333, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(test_loss)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUgR_VjKLtas"
      },
      "outputs": [],
      "source": [
        "torch.save(best_hybrid_model.state_dict(), 'best_hybrid_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grlA94uHLtas"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "084c36c94bd54cebb9de9c27765dc7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08c52b318d164ac09d087fe3eb4cc05a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c98df08accc4f3c8de06458e8441665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3889d227c01c48d9b1ddf78534c84985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c52b318d164ac09d087fe3eb4cc05a",
            "placeholder": "​",
            "style": "IPY_MODEL_084c36c94bd54cebb9de9c27765dc7bb",
            "value": "100%"
          }
        },
        "44fb5f059b8944b5a172bf9fab873810": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "56dc2650c6cc4078a4628e006c21bcec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3889d227c01c48d9b1ddf78534c84985",
              "IPY_MODEL_edf0c29d90a246aebc310eb3eb72db73",
              "IPY_MODEL_a38bb7e49c9348219c4c57b5ae296adb"
            ],
            "layout": "IPY_MODEL_44fb5f059b8944b5a172bf9fab873810"
          }
        },
        "6743934d77d944a1a1170ceaa358f0b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6fc31fddf946bcb7eaadfcc03d3f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a38bb7e49c9348219c4c57b5ae296adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6743934d77d944a1a1170ceaa358f0b5",
            "placeholder": "​",
            "style": "IPY_MODEL_7f6fc31fddf946bcb7eaadfcc03d3f6d",
            "value": " 10/10 [00:11&lt;00:00,  1.52it/s]"
          }
        },
        "decd370bee214a79a1e25aa535a1a482": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf0c29d90a246aebc310eb3eb72db73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_decd370bee214a79a1e25aa535a1a482",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c98df08accc4f3c8de06458e8441665",
            "value": 10
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}